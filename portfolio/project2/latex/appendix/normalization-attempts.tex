% vim: set spell:

\section{Normalization attempts}

\subsection{Tokenization}

Tokenization is the process of removing spaces and punctuation from the texts
in the dataset. In our case, it might also be relevant to remove the numbers.
As this seemed complicated to do with Unix tools, Python 2.7.6 was employed.

Informally, the script looks up all the texts, and replaces all sequences of
punctuation or spaces (as found in the ASCII table), by a single space. The
script follows.

\lstinputlisting[language=python]{../../../lab/2/tokenize.py}

Tokenizing both the data files and the queries in this way, did not yield any
considerably better results. Nor did upper casing all the texts subsequently.

\subsection{Stopwords}

Instead of using a handed out stopword list, an attempt was made at generating
hand-crafted stopword lists. Using an nDCG metric, and a Vector Space model
with TFIDF weighing, this approach seemed poorer in comparison. Also, not using
a stopword list yielded worse results.

The normalization technique is presented for the abstract dataset only.

We can start by extracting the words in the texts, and obtaining the 40 most
frequent words.

% http://www.real-world-systems.com/docs/tr.1.html

\begin{lstlisting}
$ grep -Pzo "(?s)<TEXT>.*?</TEXT>" abstract.sgml | \ # Extract only the texts.
    sed '/^<\/\?TEXT>/d' | \ # Remove all <TEXT> and </TEXT> tags.
    tr '[:upper:]' '[:lower:]' | \ # Lower-case everything.
    tr -s '[[:punct:][:space:]]' '\n' \ # Replace seq. of punct. or space by \n.
    > abstract.words.txt # Store result in abstract.words.txt.
$ sort abstract.words.txt | \ # Sort the words.
    uniq -c | \ # Select only unique words, count occurrences.
    sort -nr | \ # Sort numerically in nonincreasing order.
    head -40 | \ # Select the top 40.
    > abstract.stopwords.txt # Store result in abstract.stopwords.txt.
\end{lstlisting}

We can now handpick the list of stopwords, by considering their count and
semantic relation to the problem domain (cystic fibrosis). Here's one possible
result:

\begin{lstlisting}
$ cat abstract.stopwords.txt 
the
of
in
and
with
to
a
was
were
from
for
is
by
that
or
be
as
this
than
an
these
are
had
at
have
\end{lstlisting}

